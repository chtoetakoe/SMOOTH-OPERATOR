{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Notebook 01 â€” Data Exploration\n",
    "\n",
    "## Formula 1 Race Performance Analysis (2018-2024)\n",
    "\n",
    "---\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1 | Load raw CSV files from Ergast F1 Database |\n",
    "| 2 | Examine structure, columns, and data types |\n",
    "| 3 | Analyze missing values and data quality |\n",
    "| 4 | Understand relationships between tables |\n",
    "| 5 | Create base merged dataset for preprocessing |\n",
    "\n",
    "### Output\n",
    "\n",
    "dataset saved to: `../data/processed/f1_base_2018_2024.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Setup & Imports](#1-setup)\n",
    "2. [Load Raw Data](#2-load)\n",
    "3. [Data Overview](#3-overview)\n",
    "4. [Explore Each Table](#4-explore)\n",
    "5. [Missing Values Analysis](#5-missing)\n",
    "6. [Data Visualization](#6-visualization)\n",
    "7. [Create Base Dataset](#7-merge)\n",
    "8. [Save & Summary](#8-save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Imports <a id='1-setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "\n",
    "DATA_RAW = Path('../data/raw')\n",
    "DATA_PROCESSED = Path('../data/processed')\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Raw data folder: {DATA_RAW.resolve()}\")\n",
    "print(f\"Processed folder: {DATA_PROCESSED.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking available raw data files\n",
    "print(\"Raw folder exists:\", DATA_RAW.exists())\n",
    "print()\n",
    "print(\"Available CSV files:\")\n",
    "csv_files = sorted([p.name for p in DATA_RAW.glob('*.csv')])\n",
    "for f in csv_files:\n",
    "    print(f\"   - {f}\")\n",
    "print(f\"\\nTotal: {len(csv_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Raw Data <a id='2-load'></a>\n",
    "\n",
    " load the 5 main tables needed for our analysis:\n",
    "\n",
    "| Table | Description | Key Columns |\n",
    "|-------|-------------|-------------|\n",
    "| `races.csv` | Race events info | raceId, year, name, date, circuitId |\n",
    "| `results.csv` | Race results per driver | resultId, raceId, driverId, grid, position, points |\n",
    "| `drivers.csv` | Driver information | driverId, forename, surname, nationality |\n",
    "| `constructors.csv` | Team information | constructorId, name, nationality |\n",
    "| `status.csv` | Finish status codes | statusId, status (Finished, DNF reason, etc.) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV file from the raw data folder with error handling.\"\"\"\n",
    "    path = DATA_RAW / name\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing {path}. Please check your data/raw folder.\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "#main tables\n",
    "races = load_csv('races.csv')\n",
    "results = load_csv('results.csv')\n",
    "drivers = load_csv('drivers.csv')\n",
    "constructors = load_csv('constructors.csv')\n",
    "\n",
    "#status table\n",
    "status_path = DATA_RAW / 'status.csv'\n",
    "status = pd.read_csv(status_path) if status_path.exists() else None\n",
    "\n",
    "print(\"All tables loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Overview <a id='3-overview'></a>\n",
    "\n",
    "Let's get a high-level view of all tables before diving into details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overview-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of all tables\n",
    "tables = {\n",
    "    'races': races,\n",
    "    'results': results,\n",
    "    'drivers': drivers,\n",
    "    'constructors': constructors,\n",
    "    'status': status\n",
    "}\n",
    "\n",
    "summary_data = []\n",
    "for name, df in tables.items():\n",
    "    if df is not None:\n",
    "        summary_data.append({\n",
    "            'Table': name,\n",
    "            'Rows': df.shape[0],\n",
    "            'Columns': df.shape[1],\n",
    "            'Memory (KB)': round(df.memory_usage(deep=True).sum() / 1024, 1),\n",
    "            'Missing Values': df.isna().sum().sum(),\n",
    "            'Missing %': round(df.isna().sum().sum() / (df.shape[0] * df.shape[1]) * 100, 2)\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA OVERVIEW - ALL TABLES\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "key-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show columns for each table\n",
    "print(\"COLUMNS IN EACH TABLE:\")\n",
    "print(\"=\" * 70)\n",
    "for name, df in tables.items():\n",
    "    if df is not None:\n",
    "        print(f\"\\n{name.upper()} ({df.shape[1]} columns):\")\n",
    "        print(f\"   {', '.join(df.columns.tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Explore Each Table <a id='4-explore'></a>\n",
    "\n",
    "examining each table in detail: first rows, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-races",
   "metadata": {},
   "source": [
    "### 4.1 Races Table\n",
    "\n",
    "Contains information about each F1 race event (Grand Prix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "races-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RACES TABLE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {races.shape[0]} rows x {races.shape[1]} columns\")\n",
    "print(f\"Year range: {races['year'].min()} - {races['year'].max()}\")\n",
    "print(f\"Unique circuits: {races['circuitId'].nunique()}\")\n",
    "print()\n",
    "races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "races-dtypes",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data types\n",
    "print(\"Data Types:\")\n",
    "print(races.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-results",
   "metadata": {},
   "source": [
    "### 4.2 Results Table\n",
    "\n",
    "contains race results for each driver in each race. this is **main table**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS TABLE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {results.shape[0]} rows x {results.shape[1]} columns\")\n",
    "print(f\"Unique races: {results['raceId'].nunique()}\")\n",
    "print(f\"Unique drivers: {results['driverId'].nunique()}\")\n",
    "print(f\"Points range: {results['points'].min()} - {results['points'].max()}\")\n",
    "print()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-dtypes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data Types:\")\n",
    "print(results.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-drivers",
   "metadata": {},
   "source": [
    "### 4.3 Drivers Table\n",
    "\n",
    "Contains driver biographical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drivers-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DRIVERS TABLE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {drivers.shape[0]} rows x {drivers.shape[1]} columns\")\n",
    "print(f\"Unique nationalities: {drivers['nationality'].nunique()}\")\n",
    "print()\n",
    "drivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drivers-dtypes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data Types:\")\n",
    "print(drivers.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-constructors",
   "metadata": {},
   "source": [
    "### 4.4 Constructors Table\n",
    "\n",
    "Contains team (constructor) information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constructors-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONSTRUCTORS TABLE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {constructors.shape[0]} rows x {constructors.shape[1]} columns\")\n",
    "print(f\"Unique nationalities: {constructors['nationality'].nunique()}\")\n",
    "print()\n",
    "constructors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constructors-dtypes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data Types:\")\n",
    "print(constructors.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-status",
   "metadata": {},
   "source": [
    "### 4.5 Status Table\n",
    "\n",
    "Contains finish status codes (Finished, DNF reasons, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "status-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "if status is not None:\n",
    "    print(\"STATUS TABLE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Shape: {status.shape[0]} rows x {status.shape[1]} columns\")\n",
    "    print()\n",
    "    print(\"Sample status codes:\")\n",
    "    display(status.head(15))\n",
    "else:\n",
    "    print(\"Status table not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Missing Values Analysis <a id='5-missing'></a>\n",
    "\n",
    "Understanding missing data is critical for preprocessing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_report(df: pd.DataFrame, table_name: str = \"Table\") -> pd.DataFrame:\n",
    "    \"\"\"Generate a missing values report for a dataframe.\"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    missing_pct = (df.isna().sum() / len(df) * 100).round(2)\n",
    "    \n",
    "    report = pd.DataFrame({\n",
    "        'Column': missing.index,\n",
    "        'Missing Count': missing.values,\n",
    "        'Missing %': missing_pct.values,\n",
    "        'Dtype': df.dtypes.values\n",
    "    })\n",
    "    \n",
    "    return report[report['Missing Count'] > 0].sort_values('Missing %', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values in Results table(important)\n",
    "print(\"MISSING VALUES - RESULTS TABLE\")\n",
    "print(\"=\" * 50)\n",
    "missing_results = missing_report(results, 'results')\n",
    "if len(missing_results) > 0:\n",
    "    display(missing_results)\n",
    "else:\n",
    "    print(\"No missing values in results table!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-races",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values in Races table\n",
    "print(\"MISSING VALUES - RACES TABLE\")\n",
    "print(\"=\" * 50)\n",
    "missing_races = missing_report(races, 'races')\n",
    "if len(missing_races) > 0:\n",
    "    display(missing_races.head(10))\n",
    "else:\n",
    "    print(\"No missing values in races table!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for special values like \\N (Ergast uses this for NULL)\n",
    "print(\"SPECIAL VALUES CHECK\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nChecking for '\\\\N' values (Ergast NULL marker):\")\n",
    "\n",
    "for name, df in [('results', results), ('races', races)]:\n",
    "    backslash_n_count = (df == '\\\\N').sum().sum()\n",
    "    if backslash_n_count > 0:\n",
    "        print(f\"   {name}: {backslash_n_count} '\\\\N' values found\")\n",
    "        cols_with_backslash = df.columns[(df == '\\\\N').any()].tolist()\n",
    "        print(f\"   Columns: {cols_with_backslash}\")\n",
    "    else:\n",
    "        print(f\"   {name}: No '\\\\N' values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Data Visualization <a id='6-visualization'></a>\n",
    "\n",
    "visualizations to understand the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-races-per-year",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Races per year\n",
    "races_per_year = races.groupby('year').size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "races_per_year.plot(kind='bar', ax=ax, color=\"#B92214\", edgecolor='black')\n",
    "ax.set_title('Number of Races per Year (All F1 History)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Number of Races', fontsize=12)\n",
    "ax.axhline(y=races_per_year.mean(), color='black', linestyle='--', label=f'Average: {races_per_year.mean():.1f}')\n",
    "ax.legend()\n",
    "\n",
    "#Show only every 5th year label\n",
    "tick_positions = range(0, len(races_per_year), 5)\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(races_per_year.index[::5], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRecent years (2018-2024): {races_per_year.loc[2018:2024].sum()} races\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-points-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Points distribution in results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "#points histogram\n",
    "axes[0].hist(results['points'], bins=30, color=\"#c7301c\", edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Race Points (All Results)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Points')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "#grid position histogram\n",
    "grid_clean = pd.to_numeric(results['grid'], errors='coerce')\n",
    "axes[1].hist(grid_clean.dropna(), bins=20, color=\"#eb9e11\", edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Distribution of Grid Positions', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Grid Position')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-drivers-nationality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 driver nationalities\n",
    "top_nationalities = drivers['nationality'].value_counts().head(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "top_nationalities.plot(kind='barh', ax=ax, color='#38383f', edgecolor='black')\n",
    "ax.set_title('Top 10 Driver Nationalities (All Time)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Drivers')\n",
    "ax.set_ylabel('Nationality')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Create Base Dataset <a id='7-merge'></a>\n",
    "\n",
    "merge the tables to create a base dataset for preprocessing.\n",
    "\n",
    "### Merge Strategy\n",
    "\n",
    "```\n",
    "results (main table)\n",
    "    |-- JOIN races ON raceId        -> Get year, date, race name\n",
    "    |-- JOIN drivers ON driverId    -> Get driver name, nationality\n",
    "    +-- JOIN constructors ON constructorId -> Get team name\n",
    "```\n",
    "\n",
    "### Filter: 2018-2024 Only\n",
    "\n",
    "focus on the modern hybrid era for more relevant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-races",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1:filter races to 2018-2024\n",
    "races_filtered = races.loc[\n",
    "    (races['year'] >= 2018) & (races['year'] <= 2024),\n",
    "    ['raceId', 'year', 'round', 'name', 'date']\n",
    "].copy()\n",
    "\n",
    "print(f\"Races filtered to 2018-2024: {len(races_filtered)} races\")\n",
    "print(f\"Years: {races_filtered['year'].min()} - {races_filtered['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: merge results with filtered races\n",
    "base = results.merge(races_filtered, on='raceId', how='inner')\n",
    "print(f\"After merging with races: {len(base)} rows\")\n",
    "\n",
    "# step 3:prepare driver names\n",
    "drivers_small = drivers[['driverId', 'forename', 'surname', 'nationality']].copy()\n",
    "drivers_small['driverName'] = drivers_small['forename'].astype(str) + ' ' + drivers_small['surname'].astype(str)\n",
    "\n",
    "#step 4:merge with drivers\n",
    "base = base.merge(\n",
    "    drivers_small[['driverId', 'driverName', 'nationality']], \n",
    "    on='driverId', \n",
    "    how='left'\n",
    ")\n",
    "print(f\"After merging with drivers: {len(base)} rows\")\n",
    "\n",
    "#step 5:Prepare constructor names\n",
    "constructors_small = constructors[['constructorId', 'name']].copy()\n",
    "constructors_small = constructors_small.rename(columns={'name': 'constructorName'})\n",
    "\n",
    "#step 6:merge with constructors\n",
    "base = base.merge(\n",
    "    constructors_small[['constructorId', 'constructorName']], \n",
    "    on='constructorId', \n",
    "    how='left'\n",
    ")\n",
    "print(f\"After merging with constructors: {len(base)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7:select and order columns for the base dataset\n",
    "keep_cols = [\n",
    "    'raceId', 'year', 'round', 'name', 'date',           #race info\n",
    "    'driverId', 'driverName', 'nationality',              #driver info\n",
    "    'constructorId', 'constructorName',                   # team info\n",
    "    'grid', 'positionOrder', 'points',                    #results\n",
    "]\n",
    "\n",
    "#adding statusId if available\n",
    "if 'statusId' in base.columns:\n",
    "    keep_cols.append('statusId')\n",
    "\n",
    "base = base[keep_cols].copy()\n",
    "\n",
    "#convert date to datetime\n",
    "base['date'] = pd.to_datetime(base['date'], errors='coerce')\n",
    "\n",
    "print(f\"\\nBase dataset created!\")\n",
    "print(f\"Shape: {base.shape[0]} rows x {base.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-base",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview base dataset\n",
    "print(\"BASE DATASET PREVIEW\")\n",
    "print(\"=\" * 50)\n",
    "base.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "base-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "print(\"BASE DATASET INFO\")\n",
    "print(\"=\" * 50)\n",
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "base-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "print(\"BASE DATASET STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "display(base.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "base-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of the base dataset\n",
    "print(\"BASE DATASET SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records:      {len(base):,}\")\n",
    "print(f\"Unique races:       {base['raceId'].nunique()}\")\n",
    "print(f\"Unique drivers:     {base['driverId'].nunique()}\")\n",
    "print(f\"Unique teams:       {base['constructorId'].nunique()}\")\n",
    "print(f\"Year range:         {base['year'].min()} - {base['year'].max()}\")\n",
    "print(f\"Date range:         {base['date'].min().date()} to {base['date'].max().date()}\")\n",
    "print(f\"Points range:       {base['points'].min()} - {base['points'].max()}\")\n",
    "print(f\"Grid positions:     {int(base['grid'].min())} - {int(base['grid'].max())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Save & Summary <a id='8-save'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-base",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving base dataset\n",
    "OUT_PATH = DATA_PROCESSED / 'f1_base_2018_2024.csv'\n",
    "base.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(f\"Base dataset saved to: {OUT_PATH.resolve()}\")\n",
    "print(f\"File size: {OUT_PATH.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final summary\n",
    "print(\"=\" * 70)\n",
    "print(\"NOTEBOOK 01 COMPLETE - DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"RAW DATA LOADED:\")\n",
    "print(f\"   - races.csv:        {races.shape[0]:,} rows\")\n",
    "print(f\"   - results.csv:      {results.shape[0]:,} rows\")\n",
    "print(f\"   - drivers.csv:      {drivers.shape[0]:,} rows\")\n",
    "print(f\"   - constructors.csv: {constructors.shape[0]:,} rows\")\n",
    "print(f\"   - status.csv:       {status.shape[0] if status is not None else 'N/A':,} rows\")\n",
    "print()\n",
    "print(\"BASE DATASET CREATED:\")\n",
    "print(f\"   - Records:  {base.shape[0]:,} driver-race entries\")\n",
    "print(f\"   - Columns:  {base.shape[1]}\")\n",
    "print(f\"   - Years:    2018-2024 (modern hybrid era)\")\n",
    "print(f\"   - Output:   {OUT_PATH.name}\")\n",
    "print()\n",
    "print(\"NEXT STEP:\")\n",
    "print(\"   -> Notebook 02: Data Preprocessing & Feature Engineering\")\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
